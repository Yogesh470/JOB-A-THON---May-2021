{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JOB-A-THON2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZWNFR2Kr2hU"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "#from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import scipy.stats as stats\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict,KFold, StratifiedKFold\n",
        "from sklearn.naive_bayes import GaussianNB\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "quRkCdPftU2G",
        "outputId": "85fc8d88-bd86-4d2d-fd73-04548c8f92b3"
      },
      "source": [
        "df=pd.read_csv('/content/train_s3TEQDk.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Channel_Code</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Credit_Product</th>\n",
              "      <th>Avg_Account_Balance</th>\n",
              "      <th>Is_Active</th>\n",
              "      <th>Is_Lead</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NNVBBKZB</td>\n",
              "      <td>Female</td>\n",
              "      <td>73</td>\n",
              "      <td>RG268</td>\n",
              "      <td>Other</td>\n",
              "      <td>X3</td>\n",
              "      <td>43</td>\n",
              "      <td>No</td>\n",
              "      <td>1045696</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IDD62UNG</td>\n",
              "      <td>Female</td>\n",
              "      <td>30</td>\n",
              "      <td>RG277</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>32</td>\n",
              "      <td>No</td>\n",
              "      <td>581988</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>HD3DSEMC</td>\n",
              "      <td>Female</td>\n",
              "      <td>56</td>\n",
              "      <td>RG268</td>\n",
              "      <td>Self_Employed</td>\n",
              "      <td>X3</td>\n",
              "      <td>26</td>\n",
              "      <td>No</td>\n",
              "      <td>1484315</td>\n",
              "      <td>Yes</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>BF3NC7KV</td>\n",
              "      <td>Male</td>\n",
              "      <td>34</td>\n",
              "      <td>RG270</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>19</td>\n",
              "      <td>No</td>\n",
              "      <td>470454</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEASRWXV</td>\n",
              "      <td>Female</td>\n",
              "      <td>30</td>\n",
              "      <td>RG282</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>886787</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  Gender  Age  ... Avg_Account_Balance Is_Active Is_Lead\n",
              "0  NNVBBKZB  Female   73  ...             1045696        No       0\n",
              "1  IDD62UNG  Female   30  ...              581988        No       0\n",
              "2  HD3DSEMC  Female   56  ...             1484315       Yes       0\n",
              "3  BF3NC7KV    Male   34  ...              470454        No       0\n",
              "4  TEASRWXV  Female   30  ...              886787        No       0\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "stEVHqgQtleS",
        "outputId": "1f05cec1-6232-463a-8ab9-52a8309b9c5c"
      },
      "source": [
        "df2=pd.read_csv('/content/test_mSzZ8RL.csv')\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Channel_Code</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Credit_Product</th>\n",
              "      <th>Avg_Account_Balance</th>\n",
              "      <th>Is_Active</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>VBENBARO</td>\n",
              "      <td>Male</td>\n",
              "      <td>29</td>\n",
              "      <td>RG254</td>\n",
              "      <td>Other</td>\n",
              "      <td>X1</td>\n",
              "      <td>25</td>\n",
              "      <td>Yes</td>\n",
              "      <td>742366</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CCMEWNKY</td>\n",
              "      <td>Male</td>\n",
              "      <td>43</td>\n",
              "      <td>RG268</td>\n",
              "      <td>Other</td>\n",
              "      <td>X2</td>\n",
              "      <td>49</td>\n",
              "      <td>NaN</td>\n",
              "      <td>925537</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>VK3KGA9M</td>\n",
              "      <td>Male</td>\n",
              "      <td>31</td>\n",
              "      <td>RG270</td>\n",
              "      <td>Salaried</td>\n",
              "      <td>X1</td>\n",
              "      <td>14</td>\n",
              "      <td>No</td>\n",
              "      <td>215949</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TT8RPZVC</td>\n",
              "      <td>Male</td>\n",
              "      <td>29</td>\n",
              "      <td>RG272</td>\n",
              "      <td>Other</td>\n",
              "      <td>X1</td>\n",
              "      <td>33</td>\n",
              "      <td>No</td>\n",
              "      <td>868070</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SHQZEYTZ</td>\n",
              "      <td>Female</td>\n",
              "      <td>29</td>\n",
              "      <td>RG270</td>\n",
              "      <td>Other</td>\n",
              "      <td>X1</td>\n",
              "      <td>19</td>\n",
              "      <td>No</td>\n",
              "      <td>657087</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ID  Gender  Age  ... Credit_Product Avg_Account_Balance Is_Active\n",
              "0  VBENBARO    Male   29  ...            Yes              742366        No\n",
              "1  CCMEWNKY    Male   43  ...            NaN              925537        No\n",
              "2  VK3KGA9M    Male   31  ...             No              215949        No\n",
              "3  TT8RPZVC    Male   29  ...             No              868070        No\n",
              "4  SHQZEYTZ  Female   29  ...             No              657087        No\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyNGx-nqcZxs"
      },
      "source": [
        "df3 = df.append(df2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqeGEGo1v5XQ"
      },
      "source": [
        "df3['Credit_Product']=df3['Credit_Product'].fillna(-99)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAFzEgkOy7GR",
        "outputId": "d3a2e208-42b9-4145-8604-d091bea3306b"
      },
      "source": [
        "df3.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Gender                                            0\n",
              "Age                                               0\n",
              "Region_Code                                       0\n",
              "Occupation                                        0\n",
              "Channel_Code                                      0\n",
              "                                                 ..\n",
              "city_aggregate_features5Gender_count              0\n",
              "city_aggregate_features5Credit_Product_nunique    0\n",
              "city_aggregate_features5Credit_Product_count      0\n",
              "city_aggregate_features5Is_Active_nunique         0\n",
              "city_aggregate_features5Is_Active_count           0\n",
              "Length: 137, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7a2IA50x02i"
      },
      "source": [
        "df3['Vintage']= df3['Vintage']/12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d4_lyNoxHvG"
      },
      "source": [
        "df3['Gender']=df3['Gender'].replace({'Male':1,'Female':0})\n",
        "df3['Occupation']=df3['Occupation'].replace({'Self_Employed':0,'Salaried':1,'Other':2,'Entrepreneur':3})\n",
        "df3['Channel_Code']=df3['Channel_Code'].replace({'X1':1,'X3':2,'X2':3,'X4':4})\n",
        "#df['Credit_Product']=df['Credit_Product'].replace({'No':1,'Yes':2})\n",
        "df3['Is_Active']=df3['Is_Active'].replace({'No':0,'Yes':1})\n",
        "df3['Credit_Product']=df3['Credit_Product'].replace({'No':0,'Yes':1})\n",
        "\n",
        "#df3['Avg_Account_Balance']=np.log1p(df3['Avg_Account_Balance'])\n",
        "df3['Age_Group'] = np.where((df3['Age']<30) & (df3['Age'] > 60),0,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vt3grMT4Ddia"
      },
      "source": [
        "combine_set=df3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOcTJ76HDUrc"
      },
      "source": [
        "combine_set['Total_premium_Channelwise']=combine_set.groupby(['Vintage'])['Avg_Account_Balance'].transform('sum')\n",
        "combine_set['Mean_premium_Channelwise']=combine_set.groupby(['Vintage'])['Avg_Account_Balance'].transform('mean')\n",
        "combine_set['Maximum_premium_Channelwise']=combine_set.groupby(['Vintage'])['Avg_Account_Balance'].transform('max')\n",
        "combine_set['Min_premium_Channelwise']=combine_set.groupby(['Vintage'])['Avg_Account_Balance'].transform('min')\n",
        "combine_set['Total_premium_regionwise']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].transform('sum')\n",
        "combine_set['Mean_premium_regionwise']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].transform('mean')\n",
        "combine_set['Max_premium_regionwise']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].transform('max')\n",
        "combine_set['Min_premium_regionwise']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].transform('min')\n",
        "combine_set['Age_groups_region_wise']=combine_set.groupby(['Region_Code'])['Age'].transform('nunique')\n",
        "combine_set['regionwise_channels']=combine_set.groupby(['Vintage'])['Region_Code'].transform('nunique')\n",
        "combine_set['Channelwise_regions']=combine_set.groupby(['Region_Code'])['Vintage'].transform('nunique')\n",
        "combine_set['Unique_customers_based_Vinatge']=combine_set.groupby(['Region_Code','Gender'])['Vintage'].transform('nunique')\n",
        "combine_set['Region_wise_Vehicle_Age_premium']=combine_set.groupby(['Region_Code','Occupation'])['Avg_Account_Balance'].transform('sum')\n",
        "combine_set['Region_wise_Vehicle_Age_premium_mean']=combine_set.groupby(['Region_Code','Occupation'])['Avg_Account_Balance'].transform('mean')\n",
        "combine_set['Region_wise_Vehicle_Age_premium_max']=combine_set.groupby(['Region_Code','Occupation'])['Avg_Account_Balance'].transform('max')\n",
        "combine_set['Channel_wise_Vehicle_Age_premium']=combine_set.groupby(['Channel_Code', 'Occupation'])['Avg_Account_Balance'].transform('sum')\n",
        "combine_set['Channel_wise_Vehicle_Age_premium_mean']=combine_set.groupby(['Channel_Code', 'Occupation'])['Avg_Account_Balance'].transform('mean')\n",
        "combine_set['Channel_wise_Vehicle_Age_premium_max']=combine_set.groupby(['Channel_Code', 'Occupation'])['Avg_Account_Balance'].transform('max')\n",
        "\n",
        "\n",
        "combine_set['Rank_regionwise_premium']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].rank(method='first',ascending=True)\n",
        "combine_set['Rank_mean_regionwise_premium']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].rank(method='average',ascending=True)\n",
        "combine_set['Rank_max_regionwise_premium']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].rank(method='max',ascending=True)\n",
        "combine_set['Rank_min_regionwise_premium']=combine_set.groupby(['Region_Code'])['Avg_Account_Balance'].rank(method='min',ascending=True)\n",
        "combine_set['Rank_regionwise_diff']=combine_set['Rank_max_regionwise_premium']- combine_set['Rank_min_regionwise_premium']\n",
        "combine_set['Rank_channelwise_premium']=combine_set.groupby(['Channel_Code'])['Avg_Account_Balance'].rank(method='first',ascending=True)\n",
        "combine_set['Rank_mean_channelwise_premium']=combine_set.groupby(['Channel_Code'])['Avg_Account_Balance'].rank(method='average',ascending=True)\n",
        "combine_set['Rank_max_channelwise_premium']=combine_set.groupby(['Channel_Code'])['Avg_Account_Balance'].rank(method='max',ascending=True)\n",
        "combine_set['Rank_min_channelwise_premium']=combine_set.groupby(['Channel_Code'])['Avg_Account_Balance'].rank(method='min',ascending=True)\n",
        "combine_set['Rank_channelwise_diff']=combine_set['Rank_max_channelwise_premium']- combine_set['Rank_min_channelwise_premium']\n",
        "combine_set['Rank_Channel_wise_Vehicle_Age_Premium']=combine_set.groupby(['Channel_Code','Age'])['Avg_Account_Balance'].rank(method='first',ascending=True)\n",
        "combine_set['Rank_Region_wise_Vehicle_Age_premium']=combine_set.groupby(['Region_Code','Age'])['Avg_Account_Balance'].rank(method='first',ascending=True)\n",
        "combine_set['Rank_Age_wise_premium']=combine_set.groupby(['Age'])['Avg_Account_Balance'].rank(method='first',ascending=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZZrJ7d43_mj"
      },
      "source": [
        "combine_set['InsuranceLicense'] = combine_set['Is_Active'].astype('str') + '' + combine_set['Credit_Product'].astype('str')\n",
        "combine_set['InsuranceGender'] = combine_set['Is_Active'].astype('str') + '' + combine_set['Occupation'].astype('str')\n",
        "combine_set['InsuranceGender1'] = combine_set['Is_Active'].astype('str') + '' + combine_set['Channel_Code'].astype('str')\n",
        "combine_set['InsuranceGender2'] = combine_set['Gender'].astype('str') + '' + combine_set['Credit_Product'].astype('str')\n",
        "combine_set['InsuranceGender3'] = combine_set['Gender'].astype('str') + '' + combine_set['Occupation'].astype('str')\n",
        "combine_set['InsuranceGender4'] = combine_set['Gender'].astype('str') + '' + combine_set['Channel_Code'].astype('str')\n",
        "combine_set['InsuranceGender5'] = combine_set['Occupation'].astype('str') + '' + combine_set['Channel_Code'].astype('str')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRpWPZAyu4Tw"
      },
      "source": [
        "city_aggregate_features = df3.groupby(['Region_Code']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                           'Vintage': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                                     'Occupation': ['nunique','count'],\n",
        "                                                     'Channel_Code': ['nunique','count'] ,\n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features.columns = ['city_aggregate_features' + '_'.join(c).strip('_') for c in city_aggregate_features.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features, on = ['Region_Code'], how='left')\n",
        "city_aggregate_features1 = df3.groupby(['Region_Code','Vintage']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                                     'Occupation': ['nunique','count'],\n",
        "                                                     'Channel_Code': ['nunique','count'] ,\n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features1.columns = ['city_aggregate_features1' + '_'.join(c).strip('_') for c in city_aggregate_features1.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features1, on = ['Region_Code','Vintage'], how='left')\n",
        "\n",
        "city_aggregate_features2 = df3.groupby(['Region_Code','Occupation']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                           'Vintage': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                        \n",
        "                                                     'Channel_Code': ['nunique','count'] ,\n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features2.columns = ['city_aggregate_features2' + '_'.join(c).strip('_') for c in city_aggregate_features2.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features2, on = ['Region_Code','Occupation'], how='left')\n",
        "\n",
        "city_aggregate_features3 = df3.groupby(['Region_Code','Channel_Code']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                           'Vintage': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                        \n",
        "                                                     'Occupation': ['nunique','count'] ,\n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features3.columns = ['city_aggregate_features3' + '_'.join(c).strip('_') for c in city_aggregate_features3.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features3, on = ['Region_Code','Channel_Code'], how='left')\n",
        "\n",
        "city_aggregate_features4 = df3.groupby(['Vintage','Occupation']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                           'Region_Code': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                              \n",
        "                                                     'Channel_Code': ['nunique','count'] ,\n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features4.columns = ['city_aggregate_features4' + '_'.join(c).strip('_') for c in city_aggregate_features4.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features4, on = ['Vintage','Occupation'], how='left')\n",
        "\n",
        "city_aggregate_features5 = df3.groupby(['Vintage','Channel_Code']).agg({'Age': ['mean', 'max', 'min','std'],\n",
        "                                                           'Region_Code': ['mean', 'max', 'min','std'],\n",
        "                                                     'Avg_Account_Balance': ['mean', 'max', 'min','std','sum'], \n",
        "                                                     'Occupation': ['nunique','count'],\n",
        "                \n",
        "                                                     'Gender': ['nunique','count'] ,\n",
        "                                                     'Credit_Product': ['nunique','count'] ,\n",
        "                                                     'Is_Active': ['nunique','count'] ,\n",
        "                                                     })\n",
        "city_aggregate_features5.columns = ['city_aggregate_features5' + '_'.join(c).strip('_') for c in city_aggregate_features5.columns]\n",
        "df3 = pd.merge(df3, city_aggregate_features5, on = ['Vintage','Channel_Code'], how='left')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "PNzEBY5ezM3F",
        "outputId": "1ae53aa3-f7c5-4bce-b421-f25dd3115c55"
      },
      "source": [
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Region_Code</th>\n",
              "      <th>Occupation</th>\n",
              "      <th>Channel_Code</th>\n",
              "      <th>Vintage</th>\n",
              "      <th>Credit_Product</th>\n",
              "      <th>Avg_Account_Balance</th>\n",
              "      <th>Is_Active</th>\n",
              "      <th>Is_Lead</th>\n",
              "      <th>Age_Group</th>\n",
              "      <th>Total_premium_Channelwise</th>\n",
              "      <th>Mean_premium_Channelwise</th>\n",
              "      <th>Maximum_premium_Channelwise</th>\n",
              "      <th>Min_premium_Channelwise</th>\n",
              "      <th>Total_premium_regionwise</th>\n",
              "      <th>Mean_premium_regionwise</th>\n",
              "      <th>Max_premium_regionwise</th>\n",
              "      <th>Min_premium_regionwise</th>\n",
              "      <th>Age_groups_region_wise</th>\n",
              "      <th>regionwise_channels</th>\n",
              "      <th>Channelwise_regions</th>\n",
              "      <th>Unique_customers_based_Vinatge</th>\n",
              "      <th>Region_wise_Vehicle_Age_premium</th>\n",
              "      <th>Region_wise_Vehicle_Age_premium_mean</th>\n",
              "      <th>Region_wise_Vehicle_Age_premium_max</th>\n",
              "      <th>Channel_wise_Vehicle_Age_premium</th>\n",
              "      <th>Channel_wise_Vehicle_Age_premium_mean</th>\n",
              "      <th>Channel_wise_Vehicle_Age_premium_max</th>\n",
              "      <th>Rank_regionwise_premium</th>\n",
              "      <th>Rank_mean_regionwise_premium</th>\n",
              "      <th>Rank_max_regionwise_premium</th>\n",
              "      <th>Rank_min_regionwise_premium</th>\n",
              "      <th>Rank_regionwise_diff</th>\n",
              "      <th>Rank_channelwise_premium</th>\n",
              "      <th>Rank_mean_channelwise_premium</th>\n",
              "      <th>Rank_max_channelwise_premium</th>\n",
              "      <th>Rank_min_channelwise_premium</th>\n",
              "      <th>Rank_channelwise_diff</th>\n",
              "      <th>Rank_Channel_wise_Vehicle_Age_Premium</th>\n",
              "      <th>...</th>\n",
              "      <th>InsuranceGender1_13</th>\n",
              "      <th>InsuranceGender1_14</th>\n",
              "      <th>InsuranceGender2_0-99</th>\n",
              "      <th>InsuranceGender2_00</th>\n",
              "      <th>InsuranceGender2_01</th>\n",
              "      <th>InsuranceGender2_1-99</th>\n",
              "      <th>InsuranceGender2_10</th>\n",
              "      <th>InsuranceGender2_11</th>\n",
              "      <th>InsuranceGender3_00</th>\n",
              "      <th>InsuranceGender3_01</th>\n",
              "      <th>InsuranceGender3_02</th>\n",
              "      <th>InsuranceGender3_03</th>\n",
              "      <th>InsuranceGender3_10</th>\n",
              "      <th>InsuranceGender3_11</th>\n",
              "      <th>InsuranceGender3_12</th>\n",
              "      <th>InsuranceGender3_13</th>\n",
              "      <th>InsuranceGender4_01</th>\n",
              "      <th>InsuranceGender4_02</th>\n",
              "      <th>InsuranceGender4_03</th>\n",
              "      <th>InsuranceGender4_04</th>\n",
              "      <th>InsuranceGender4_11</th>\n",
              "      <th>InsuranceGender4_12</th>\n",
              "      <th>InsuranceGender4_13</th>\n",
              "      <th>InsuranceGender4_14</th>\n",
              "      <th>InsuranceGender5_01</th>\n",
              "      <th>InsuranceGender5_02</th>\n",
              "      <th>InsuranceGender5_03</th>\n",
              "      <th>InsuranceGender5_04</th>\n",
              "      <th>InsuranceGender5_11</th>\n",
              "      <th>InsuranceGender5_12</th>\n",
              "      <th>InsuranceGender5_13</th>\n",
              "      <th>InsuranceGender5_14</th>\n",
              "      <th>InsuranceGender5_21</th>\n",
              "      <th>InsuranceGender5_22</th>\n",
              "      <th>InsuranceGender5_23</th>\n",
              "      <th>InsuranceGender5_24</th>\n",
              "      <th>InsuranceGender5_31</th>\n",
              "      <th>InsuranceGender5_32</th>\n",
              "      <th>InsuranceGender5_33</th>\n",
              "      <th>InsuranceGender5_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>73</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>1045696</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2852149051</td>\n",
              "      <td>1.241684e+06</td>\n",
              "      <td>7779267</td>\n",
              "      <td>95114</td>\n",
              "      <td>75114665124</td>\n",
              "      <td>1.471135e+06</td>\n",
              "      <td>10352009</td>\n",
              "      <td>45950</td>\n",
              "      <td>62</td>\n",
              "      <td>35</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>24910377386</td>\n",
              "      <td>1.540149e+06</td>\n",
              "      <td>10352009</td>\n",
              "      <td>49190672720</td>\n",
              "      <td>1.347985e+06</td>\n",
              "      <td>10352009</td>\n",
              "      <td>20313.0</td>\n",
              "      <td>20313.0</td>\n",
              "      <td>20313.0</td>\n",
              "      <td>20313.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>49671.0</td>\n",
              "      <td>49671.0</td>\n",
              "      <td>49671.0</td>\n",
              "      <td>49671.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>417.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>27</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>581988</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14068133361</td>\n",
              "      <td>1.034422e+06</td>\n",
              "      <td>9090894</td>\n",
              "      <td>56185</td>\n",
              "      <td>18069009345</td>\n",
              "      <td>9.808386e+05</td>\n",
              "      <td>9672677</td>\n",
              "      <td>79850</td>\n",
              "      <td>62</td>\n",
              "      <td>35</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>6200074070</td>\n",
              "      <td>9.664963e+05</td>\n",
              "      <td>9672677</td>\n",
              "      <td>90873818778</td>\n",
              "      <td>1.008477e+06</td>\n",
              "      <td>9701151</td>\n",
              "      <td>4968.0</td>\n",
              "      <td>4968.0</td>\n",
              "      <td>4968.0</td>\n",
              "      <td>4968.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41357.0</td>\n",
              "      <td>41358.0</td>\n",
              "      <td>41359.0</td>\n",
              "      <td>41357.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4223.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>56</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>1484315</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>16092006404</td>\n",
              "      <td>1.024512e+06</td>\n",
              "      <td>9701151</td>\n",
              "      <td>76557</td>\n",
              "      <td>75114665124</td>\n",
              "      <td>1.471135e+06</td>\n",
              "      <td>10352009</td>\n",
              "      <td>45950</td>\n",
              "      <td>62</td>\n",
              "      <td>35</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>35292017443</td>\n",
              "      <td>1.400144e+06</td>\n",
              "      <td>8741290</td>\n",
              "      <td>64625208152</td>\n",
              "      <td>1.223406e+06</td>\n",
              "      <td>8680305</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>32226.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70668.0</td>\n",
              "      <td>70668.0</td>\n",
              "      <td>70668.0</td>\n",
              "      <td>70668.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2296.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>34</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>470454</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>17602048614</td>\n",
              "      <td>1.008309e+06</td>\n",
              "      <td>9307666</td>\n",
              "      <td>45950</td>\n",
              "      <td>7767689513</td>\n",
              "      <td>6.960295e+05</td>\n",
              "      <td>8086910</td>\n",
              "      <td>78818</td>\n",
              "      <td>62</td>\n",
              "      <td>35</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>3562632056</td>\n",
              "      <td>6.865739e+05</td>\n",
              "      <td>5222146</td>\n",
              "      <td>90873818778</td>\n",
              "      <td>1.008477e+06</td>\n",
              "      <td>9701151</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>2968.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24199.0</td>\n",
              "      <td>24199.5</td>\n",
              "      <td>24200.0</td>\n",
              "      <td>24199.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>742.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>886787</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>14212136644</td>\n",
              "      <td>1.040344e+06</td>\n",
              "      <td>9513952</td>\n",
              "      <td>22597</td>\n",
              "      <td>7839358912</td>\n",
              "      <td>9.599999e+05</td>\n",
              "      <td>8338925</td>\n",
              "      <td>50293</td>\n",
              "      <td>63</td>\n",
              "      <td>35</td>\n",
              "      <td>63</td>\n",
              "      <td>63</td>\n",
              "      <td>3017573796</td>\n",
              "      <td>9.712178e+05</td>\n",
              "      <td>7060467</td>\n",
              "      <td>90873818778</td>\n",
              "      <td>1.008477e+06</td>\n",
              "      <td>9701151</td>\n",
              "      <td>4124.0</td>\n",
              "      <td>4124.0</td>\n",
              "      <td>4124.0</td>\n",
              "      <td>4124.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>83294.0</td>\n",
              "      <td>83294.0</td>\n",
              "      <td>83294.0</td>\n",
              "      <td>83294.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8316.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 102 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Gender  Age  ...  InsuranceGender5_33  InsuranceGender5_34\n",
              "0       0   73  ...                    0                    0\n",
              "1       0   30  ...                    0                    0\n",
              "2       0   56  ...                    0                    0\n",
              "3       1   34  ...                    0                    0\n",
              "4       0   30  ...                    0                    0\n",
              "\n",
              "[5 rows x 102 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCivyjAHzmTX"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsc3rFi_zvqX"
      },
      "source": [
        "y=LabelEncoder()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThgG1qvPzzr-"
      },
      "source": [
        "df3['Region_Code']=y.fit_transform(df3['Region_Code'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_UlvGP2zUCX"
      },
      "source": [
        "df3.drop('ID',axis=1,inplace=True)\n",
        "#df3.drop('Credit_Product',axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0yWzgH3HTxM"
      },
      "source": [
        "df3=combine_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0rFyhqo5DHo"
      },
      "source": [
        "df3 = pd.get_dummies(df3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTV5k8pA0FIi"
      },
      "source": [
        "train_df=df3[df3['Is_Lead'].isnull()==False]\n",
        "test_df=df3[df3['Is_Lead'].isnull()==True]\n",
        "\n",
        "X=train_df.drop(['Is_Lead'],axis=1)\n",
        "y=train_df['Is_Lead'] \n",
        "X_main_test=test_df.drop(['Is_Lead'],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9rAIIxs0nEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbba706-6601-494c-8747-2d1d9f783e0c"
      },
      "source": [
        "oof_pred               = np.zeros((len(train_df),))\n",
        "y_pred_final           = np.zeros((len(test_df),))\n",
        "num_models             = 3\n",
        "\n",
        "n_splits               = 20\n",
        "error                  = []\n",
        "\n",
        "kf=StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=294)\n",
        "    \n",
        "for i,(train_idx,val_idx) in enumerate(kf.split(X,y)):    \n",
        "    \n",
        "    wghts                     = [0]*num_models\n",
        "    test_roc_score            = []\n",
        "    \n",
        "    \n",
        "    X_train, y_train = X.iloc[train_idx,:], y.iloc[train_idx]\n",
        "\n",
        "    X_val, y_val = X.iloc[val_idx, :], y.iloc[val_idx]\n",
        "    \n",
        "\n",
        "    print('\\nFold: {}\\n'.format(i+1))\n",
        "\n",
        "    model1 = LGBMClassifier(boosting_type='gbdt',n_estimators=500,depth=-1,learning_rate=0.03,scale_pos_weight=7,objective='binary',metric='auc',\n",
        "                 colsample_bytree=0.5,random_state=294,n_jobs=-1)\n",
        "    model1.fit(X_train,y_train)\n",
        "    testpred1 = model1.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred1))\n",
        "    print(\"Test ROC AUC for model 1: %.4f\"%(roc_auc_score(y_val, testpred1)))\n",
        "    \n",
        "    model2 = LGBMClassifier(boosting_type='gbdt',n_estimators=300,depth=-1,learning_rate=0.03,scale_pos_weight=7,objective='binary',metric='auc',\n",
        "                 colsample_bytree=0.3,reg_alpha=2,random_state=294,n_jobs=-1)\n",
        "    model2.fit(X_train,y_train)\n",
        "    testpred2 = model2.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred2))\n",
        "    print(\"Test ROC AUC for model 2: %.4f\"%(roc_auc_score(y_val, testpred2)))\n",
        "    \n",
        "    model3 = LGBMClassifier(boosting_type='gbdt',n_estimators=400,depth=-1,learning_rate=0.03,scale_pos_weight=7,objective='binary',metric='auc',\n",
        "                 colsample_bytree=0.4,reg_alpha=2,random_state=294,n_jobs=-1)\n",
        "    model3.fit(X_train,y_train)\n",
        "    testpred3 = model3.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred3))\n",
        "    print(\"Test ROC AUC for model 3: %.4f\"%(roc_auc_score(y_val, testpred3)))\n",
        "    \n",
        "    wghts              = np.exp(-1000*np.array(test_roc_score/sum(test_roc_score)))\n",
        "    wghts              = wghts/sum(wghts)\n",
        "    \n",
        "    val_pred           = wghts[0]*testpred1+wghts[1]*testpred2 +wghts[2]*testpred3\n",
        "    print('validation roc_auc_score fold-',i+1,': ',roc_auc_score(y_val, val_pred))\n",
        "    \n",
        "    oof_pred[val_idx]  = val_pred\n",
        "    y_pred_final += (wghts[0]*model1.predict_proba(X_main_test)[:,1]+wghts[1]*model2.predict_proba(X_main_test)[:,1]+wghts[2]*model3.predict_proba(X_main_test)[:,1])/(n_splits)\n",
        "    \n",
        "    print('\\n')\n",
        "    \n",
        "print('OOF ROC_AUC_Score:- ',(roc_auc_score(y,oof_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 1\n",
            "\n",
            "Test ROC AUC for model 1: 0.8724\n",
            "Test ROC AUC for model 2: 0.8713\n",
            "Test ROC AUC for model 3: 0.8713\n",
            "validation roc_auc_score fold- 1 :  0.8715299541936895\n",
            "\n",
            "\n",
            "\n",
            "Fold: 2\n",
            "\n",
            "Test ROC AUC for model 1: 0.8729\n",
            "Test ROC AUC for model 2: 0.8727\n",
            "Test ROC AUC for model 3: 0.8730\n",
            "validation roc_auc_score fold- 2 :  0.8728885867834483\n",
            "\n",
            "\n",
            "\n",
            "Fold: 3\n",
            "\n",
            "Test ROC AUC for model 1: 0.8783\n",
            "Test ROC AUC for model 2: 0.8791\n",
            "Test ROC AUC for model 3: 0.8792\n",
            "validation roc_auc_score fold- 3 :  0.8789041698603701\n",
            "\n",
            "\n",
            "\n",
            "Fold: 4\n",
            "\n",
            "Test ROC AUC for model 1: 0.8748\n",
            "Test ROC AUC for model 2: 0.8747\n",
            "Test ROC AUC for model 3: 0.8751\n",
            "validation roc_auc_score fold- 4 :  0.8749439408947055\n",
            "\n",
            "\n",
            "\n",
            "Fold: 5\n",
            "\n",
            "Test ROC AUC for model 1: 0.8800\n",
            "Test ROC AUC for model 2: 0.8798\n",
            "Test ROC AUC for model 3: 0.8799\n",
            "validation roc_auc_score fold- 5 :  0.8799755887578707\n",
            "\n",
            "\n",
            "\n",
            "Fold: 6\n",
            "\n",
            "Test ROC AUC for model 1: 0.8769\n",
            "Test ROC AUC for model 2: 0.8763\n",
            "Test ROC AUC for model 3: 0.8772\n",
            "validation roc_auc_score fold- 6 :  0.8767825699648276\n",
            "\n",
            "\n",
            "\n",
            "Fold: 7\n",
            "\n",
            "Test ROC AUC for model 1: 0.8726\n",
            "Test ROC AUC for model 2: 0.8734\n",
            "Test ROC AUC for model 3: 0.8735\n",
            "validation roc_auc_score fold- 7 :  0.8732450572698477\n",
            "\n",
            "\n",
            "\n",
            "Fold: 8\n",
            "\n",
            "Test ROC AUC for model 1: 0.8755\n",
            "Test ROC AUC for model 2: 0.8762\n",
            "Test ROC AUC for model 3: 0.8758\n",
            "validation roc_auc_score fold- 8 :  0.8759235991435814\n",
            "\n",
            "\n",
            "\n",
            "Fold: 9\n",
            "\n",
            "Test ROC AUC for model 1: 0.8702\n",
            "Test ROC AUC for model 2: 0.8694\n",
            "Test ROC AUC for model 3: 0.8700\n",
            "validation roc_auc_score fold- 9 :  0.8699373870560565\n",
            "\n",
            "\n",
            "\n",
            "Fold: 10\n",
            "\n",
            "Test ROC AUC for model 1: 0.8708\n",
            "Test ROC AUC for model 2: 0.8706\n",
            "Test ROC AUC for model 3: 0.8706\n",
            "validation roc_auc_score fold- 10 :  0.870807672410788\n",
            "\n",
            "\n",
            "\n",
            "Fold: 11\n",
            "\n",
            "Test ROC AUC for model 1: 0.8676\n",
            "Test ROC AUC for model 2: 0.8681\n",
            "Test ROC AUC for model 3: 0.8679\n",
            "validation roc_auc_score fold- 11 :  0.8680198848715095\n",
            "\n",
            "\n",
            "\n",
            "Fold: 12\n",
            "\n",
            "Test ROC AUC for model 1: 0.8785\n",
            "Test ROC AUC for model 2: 0.8784\n",
            "Test ROC AUC for model 3: 0.8786\n",
            "validation roc_auc_score fold- 12 :  0.8786089700156807\n",
            "\n",
            "\n",
            "\n",
            "Fold: 13\n",
            "\n",
            "Test ROC AUC for model 1: 0.8719\n",
            "Test ROC AUC for model 2: 0.8725\n",
            "Test ROC AUC for model 3: 0.8718\n",
            "validation roc_auc_score fold- 13 :  0.8719845486680194\n",
            "\n",
            "\n",
            "\n",
            "Fold: 14\n",
            "\n",
            "Test ROC AUC for model 1: 0.8687\n",
            "Test ROC AUC for model 2: 0.8692\n",
            "Test ROC AUC for model 3: 0.8691\n",
            "validation roc_auc_score fold- 14 :  0.8692178339896495\n",
            "\n",
            "\n",
            "\n",
            "Fold: 15\n",
            "\n",
            "Test ROC AUC for model 1: 0.8701\n",
            "Test ROC AUC for model 2: 0.8703\n",
            "Test ROC AUC for model 3: 0.8700\n",
            "validation roc_auc_score fold- 15 :  0.8703464129340424\n",
            "\n",
            "\n",
            "\n",
            "Fold: 16\n",
            "\n",
            "Test ROC AUC for model 1: 0.8779\n",
            "Test ROC AUC for model 2: 0.8783\n",
            "Test ROC AUC for model 3: 0.8782\n",
            "validation roc_auc_score fold- 16 :  0.8781704494557454\n",
            "\n",
            "\n",
            "\n",
            "Fold: 17\n",
            "\n",
            "Test ROC AUC for model 1: 0.8795\n",
            "Test ROC AUC for model 2: 0.8793\n",
            "Test ROC AUC for model 3: 0.8801\n",
            "validation roc_auc_score fold- 17 :  0.8797815072042453\n",
            "\n",
            "\n",
            "\n",
            "Fold: 18\n",
            "\n",
            "Test ROC AUC for model 1: 0.8728\n",
            "Test ROC AUC for model 2: 0.8728\n",
            "Test ROC AUC for model 3: 0.8727\n",
            "validation roc_auc_score fold- 18 :  0.8728951385181063\n",
            "\n",
            "\n",
            "\n",
            "Fold: 19\n",
            "\n",
            "Test ROC AUC for model 1: 0.8746\n",
            "Test ROC AUC for model 2: 0.8750\n",
            "Test ROC AUC for model 3: 0.8750\n",
            "validation roc_auc_score fold- 19 :  0.8749039086865742\n",
            "\n",
            "\n",
            "\n",
            "Fold: 20\n",
            "\n",
            "Test ROC AUC for model 1: 0.8705\n",
            "Test ROC AUC for model 2: 0.8706\n",
            "Test ROC AUC for model 3: 0.8710\n",
            "validation roc_auc_score fold- 20 :  0.8706378552276073\n",
            "\n",
            "\n",
            "OOF ROC_AUC_Score:-  0.873930966223262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gt0yUfrsHpeF",
        "outputId": "b2e6d26a-ba5d-4d17-ba74-4bea2fea7478"
      },
      "source": [
        "df3.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 351037 entries, 0 to 105311\n",
            "Data columns (total 86 columns):\n",
            " #   Column                                 Non-Null Count   Dtype  \n",
            "---  ------                                 --------------   -----  \n",
            " 0   Gender                                 351037 non-null  int64  \n",
            " 1   Age                                    351037 non-null  int64  \n",
            " 2   Region_Code                            351037 non-null  int64  \n",
            " 3   Occupation                             351037 non-null  int64  \n",
            " 4   Channel_Code                           351037 non-null  int64  \n",
            " 5   Vintage                                351037 non-null  int64  \n",
            " 6   Credit_Product                         351037 non-null  int64  \n",
            " 7   Avg_Account_Balance                    351037 non-null  int64  \n",
            " 8   Is_Active                              351037 non-null  int64  \n",
            " 9   Is_Lead                                245725 non-null  float64\n",
            " 10  Age_Group                              351037 non-null  int64  \n",
            " 11  Total_premium_Channelwise              351037 non-null  int64  \n",
            " 12  Mean_premium_Channelwise               351037 non-null  float64\n",
            " 13  Maximum_premium_Channelwise            351037 non-null  int64  \n",
            " 14  Min_premium_Channelwise                351037 non-null  int64  \n",
            " 15  Total_premium_regionwise               351037 non-null  int64  \n",
            " 16  Mean_premium_regionwise                351037 non-null  float64\n",
            " 17  Max_premium_regionwise                 351037 non-null  int64  \n",
            " 18  Min_premium_regionwise                 351037 non-null  int64  \n",
            " 19  Age_groups_region_wise                 351037 non-null  int64  \n",
            " 20  regionwise_channels                    351037 non-null  int64  \n",
            " 21  Channelwise_regions                    351037 non-null  int64  \n",
            " 22  Unique_customers_based_Vinatge         351037 non-null  int64  \n",
            " 23  Region_wise_Vehicle_Age_premium        351037 non-null  int64  \n",
            " 24  Region_wise_Vehicle_Age_premium_mean   351037 non-null  float64\n",
            " 25  Region_wise_Vehicle_Age_premium_max    351037 non-null  int64  \n",
            " 26  Channel_wise_Vehicle_Age_premium       351037 non-null  int64  \n",
            " 27  Channel_wise_Vehicle_Age_premium_mean  351037 non-null  float64\n",
            " 28  Channel_wise_Vehicle_Age_premium_max   351037 non-null  int64  \n",
            " 29  Rank_regionwise_premium                351037 non-null  float64\n",
            " 30  Rank_mean_regionwise_premium           351037 non-null  float64\n",
            " 31  Rank_max_regionwise_premium            351037 non-null  float64\n",
            " 32  Rank_min_regionwise_premium            351037 non-null  float64\n",
            " 33  Rank_regionwise_diff                   351037 non-null  float64\n",
            " 34  Rank_channelwise_premium               351037 non-null  float64\n",
            " 35  Rank_mean_channelwise_premium          351037 non-null  float64\n",
            " 36  Rank_max_channelwise_premium           351037 non-null  float64\n",
            " 37  Rank_min_channelwise_premium           351037 non-null  float64\n",
            " 38  Rank_channelwise_diff                  351037 non-null  float64\n",
            " 39  Rank_Channel_wise_Vehicle_Age_Premium  351037 non-null  float64\n",
            " 40  Rank_Region_wise_Vehicle_Age_premium   351037 non-null  float64\n",
            " 41  Rank_Age_wise_premium                  351037 non-null  float64\n",
            " 42  InsuranceLicense_0-99                  351037 non-null  uint8  \n",
            " 43  InsuranceLicense_00                    351037 non-null  uint8  \n",
            " 44  InsuranceLicense_01                    351037 non-null  uint8  \n",
            " 45  InsuranceLicense_1-99                  351037 non-null  uint8  \n",
            " 46  InsuranceLicense_10                    351037 non-null  uint8  \n",
            " 47  InsuranceLicense_11                    351037 non-null  uint8  \n",
            " 48  InsuranceGender_00                     351037 non-null  uint8  \n",
            " 49  InsuranceGender_01                     351037 non-null  uint8  \n",
            " 50  InsuranceGender_02                     351037 non-null  uint8  \n",
            " 51  InsuranceGender_03                     351037 non-null  uint8  \n",
            " 52  InsuranceGender_10                     351037 non-null  uint8  \n",
            " 53  InsuranceGender_11                     351037 non-null  uint8  \n",
            " 54  InsuranceGender_12                     351037 non-null  uint8  \n",
            " 55  InsuranceGender_13                     351037 non-null  uint8  \n",
            " 56  InsuranceGender1_01                    351037 non-null  uint8  \n",
            " 57  InsuranceGender1_02                    351037 non-null  uint8  \n",
            " 58  InsuranceGender1_03                    351037 non-null  uint8  \n",
            " 59  InsuranceGender1_04                    351037 non-null  uint8  \n",
            " 60  InsuranceGender1_11                    351037 non-null  uint8  \n",
            " 61  InsuranceGender1_12                    351037 non-null  uint8  \n",
            " 62  InsuranceGender1_13                    351037 non-null  uint8  \n",
            " 63  InsuranceGender1_14                    351037 non-null  uint8  \n",
            " 64  InsuranceGender2_0-99                  351037 non-null  uint8  \n",
            " 65  InsuranceGender2_00                    351037 non-null  uint8  \n",
            " 66  InsuranceGender2_01                    351037 non-null  uint8  \n",
            " 67  InsuranceGender2_1-99                  351037 non-null  uint8  \n",
            " 68  InsuranceGender2_10                    351037 non-null  uint8  \n",
            " 69  InsuranceGender2_11                    351037 non-null  uint8  \n",
            " 70  InsuranceGender3_00                    351037 non-null  uint8  \n",
            " 71  InsuranceGender3_01                    351037 non-null  uint8  \n",
            " 72  InsuranceGender3_02                    351037 non-null  uint8  \n",
            " 73  InsuranceGender3_03                    351037 non-null  uint8  \n",
            " 74  InsuranceGender3_10                    351037 non-null  uint8  \n",
            " 75  InsuranceGender3_11                    351037 non-null  uint8  \n",
            " 76  InsuranceGender3_12                    351037 non-null  uint8  \n",
            " 77  InsuranceGender3_13                    351037 non-null  uint8  \n",
            " 78  InsuranceGender4_01                    351037 non-null  uint8  \n",
            " 79  InsuranceGender4_02                    351037 non-null  uint8  \n",
            " 80  InsuranceGender4_03                    351037 non-null  uint8  \n",
            " 81  InsuranceGender4_04                    351037 non-null  uint8  \n",
            " 82  InsuranceGender4_11                    351037 non-null  uint8  \n",
            " 83  InsuranceGender4_12                    351037 non-null  uint8  \n",
            " 84  InsuranceGender4_13                    351037 non-null  uint8  \n",
            " 85  InsuranceGender4_14                    351037 non-null  uint8  \n",
            "dtypes: float64(18), int64(24), uint8(44)\n",
            "memory usage: 129.9 MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zCdtmnIdBhQ",
        "outputId": "9ac8ea37-3989-4d78-ea43-8909a06a6c80"
      },
      "source": [
        "df3.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code', 'Vintage',\n",
              "       'Credit_Product', 'Avg_Account_Balance', 'Is_Active', 'Is_Lead',\n",
              "       'Age_Group', 'Total_premium_Channelwise', 'Mean_premium_Channelwise',\n",
              "       'Maximum_premium_Channelwise', 'Min_premium_Channelwise',\n",
              "       'Total_premium_regionwise', 'Mean_premium_regionwise',\n",
              "       'Max_premium_regionwise', 'Min_premium_regionwise',\n",
              "       'Age_groups_region_wise', 'regionwise_channels', 'Channelwise_regions',\n",
              "       'Unique_customers_based_Vinatge', 'Region_wise_Vehicle_Age_premium',\n",
              "       'Region_wise_Vehicle_Age_premium_mean',\n",
              "       'Region_wise_Vehicle_Age_premium_max',\n",
              "       'Channel_wise_Vehicle_Age_premium',\n",
              "       'Channel_wise_Vehicle_Age_premium_mean',\n",
              "       'Channel_wise_Vehicle_Age_premium_max', 'Rank_regionwise_premium',\n",
              "       'Rank_mean_regionwise_premium', 'Rank_max_regionwise_premium',\n",
              "       'Rank_min_regionwise_premium', 'Rank_regionwise_diff',\n",
              "       'Rank_channelwise_premium', 'Rank_mean_channelwise_premium',\n",
              "       'Rank_max_channelwise_premium', 'Rank_min_channelwise_premium',\n",
              "       'Rank_channelwise_diff', 'Rank_Channel_wise_Vehicle_Age_Premium',\n",
              "       'Rank_Region_wise_Vehicle_Age_premium', 'Rank_Age_wise_premium',\n",
              "       'InsuranceLicense_0-99', 'InsuranceLicense_00', 'InsuranceLicense_01',\n",
              "       'InsuranceLicense_1-99', 'InsuranceLicense_10', 'InsuranceLicense_11',\n",
              "       'InsuranceGender_00', 'InsuranceGender_01', 'InsuranceGender_02',\n",
              "       'InsuranceGender_03', 'InsuranceGender_10', 'InsuranceGender_11',\n",
              "       'InsuranceGender_12', 'InsuranceGender_13', 'InsuranceGender1_01',\n",
              "       'InsuranceGender1_02', 'InsuranceGender1_03', 'InsuranceGender1_04',\n",
              "       'InsuranceGender1_11', 'InsuranceGender1_12', 'InsuranceGender1_13',\n",
              "       'InsuranceGender1_14', 'InsuranceGender2_0-99', 'InsuranceGender2_00',\n",
              "       'InsuranceGender2_01', 'InsuranceGender2_1-99', 'InsuranceGender2_10',\n",
              "       'InsuranceGender2_11', 'InsuranceGender3_00', 'InsuranceGender3_01',\n",
              "       'InsuranceGender3_02', 'InsuranceGender3_03', 'InsuranceGender3_10',\n",
              "       'InsuranceGender3_11', 'InsuranceGender3_12', 'InsuranceGender3_13',\n",
              "       'InsuranceGender4_01', 'InsuranceGender4_02', 'InsuranceGender4_03',\n",
              "       'InsuranceGender4_04', 'InsuranceGender4_11', 'InsuranceGender4_12',\n",
              "       'InsuranceGender4_13', 'InsuranceGender4_14'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAginowUdDp5"
      },
      "source": [
        "cat_col=['Gender', 'Age', 'Region_Code', 'Occupation', 'Channel_Code', 'Vintage',\n",
        "       'Credit_Product', 'Avg_Account_Balance', 'Is_Active',\n",
        "       'Age_Group', 'Total_premium_Channelwise',\n",
        "       'Maximum_premium_Channelwise', 'Min_premium_Channelwise',\n",
        "       'Total_premium_regionwise',\n",
        "       'Max_premium_regionwise', 'Min_premium_regionwise',\n",
        "       'Age_groups_region_wise', 'regionwise_channels', 'Channelwise_regions',\n",
        "       'Unique_customers_based_Vinatge', 'Region_wise_Vehicle_Age_premium',\n",
        "      \n",
        "       'Region_wise_Vehicle_Age_premium_max',\n",
        "       'Channel_wise_Vehicle_Age_premium',\n",
        "      \n",
        "       'Channel_wise_Vehicle_Age_premium_max',\n",
        "       'InsuranceLicense_0-99', 'InsuranceLicense_00', 'InsuranceLicense_01',\n",
        "       'InsuranceLicense_1-99', 'InsuranceLicense_10', 'InsuranceLicense_11',\n",
        "       'InsuranceGender_00', 'InsuranceGender_01', 'InsuranceGender_02',\n",
        "       'InsuranceGender_03', 'InsuranceGender_10', 'InsuranceGender_11',\n",
        "       'InsuranceGender_12', 'InsuranceGender_13', 'InsuranceGender1_01',\n",
        "       'InsuranceGender1_02', 'InsuranceGender1_03', 'InsuranceGender1_04',\n",
        "       'InsuranceGender1_11', 'InsuranceGender1_12', 'InsuranceGender1_13',\n",
        "       'InsuranceGender1_14', 'InsuranceGender2_0-99', 'InsuranceGender2_00',\n",
        "       'InsuranceGender2_01', 'InsuranceGender2_1-99', 'InsuranceGender2_10',\n",
        "       'InsuranceGender2_11', 'InsuranceGender3_00', 'InsuranceGender3_01',\n",
        "       'InsuranceGender3_02', 'InsuranceGender3_03', 'InsuranceGender3_10',\n",
        "       'InsuranceGender3_11', 'InsuranceGender3_12', 'InsuranceGender3_13',\n",
        "       'InsuranceGender4_01', 'InsuranceGender4_02', 'InsuranceGender4_03',\n",
        "       'InsuranceGender4_04', 'InsuranceGender4_11', 'InsuranceGender4_12',\n",
        "       'InsuranceGender4_13', 'InsuranceGender4_14']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fM2F0Gg6dlrM"
      },
      "source": [
        "train = df3[df3['Is_Lead'].isnull()!= True]\n",
        "test = df3[df3['Is_Lead'].isnull()== True]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxMCesaGduzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306b50fc-5110-48b1-927b-dc11ce73e3a6"
      },
      "source": [
        "test.drop(['Is_Lead'],axis=1,inplace=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv1Ywce4dzHq"
      },
      "source": [
        "X = train.drop([\"Is_Lead\"], axis=1)\n",
        "Y = train[\"Is_Lead\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TlWm2G7q16pF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adef1cd0-12d5-4f28-9194-9aca10075f3e"
      },
      "source": [
        "#train_x,test_x,train_y,test_y=train_test_split(df,df1,test_size=0.25,random_state=1,shuffle=True)\n",
        "oof_pred               = np.zeros((len(train),))\n",
        "y_pred_final           = np.zeros((len(test),))\n",
        "num_models             = 3\n",
        "\n",
        "n_splits               = 2\n",
        "error                  = []\n",
        "\n",
        "kf=StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=294)\n",
        "    \n",
        "for i,(train_idx,val_idx) in enumerate(kf.split(X,Y)):    \n",
        "    \n",
        "    wghts                     = [0]*num_models\n",
        "    test_roc_score            = []\n",
        "    \n",
        "    \n",
        "    X_train, y_train = X.iloc[train_idx,:], Y.iloc[train_idx]\n",
        "\n",
        "    X_val, y_val = X.iloc[val_idx, :], Y.iloc[val_idx]\n",
        "    \n",
        "\n",
        "    print('\\nFold: {}\\n'.format(i+1))\n",
        "\n",
        "    model1 = cat.CatBoostClassifier(learning_rate = 0.03,random_state=42,scale_pos_weight=7, custom_metric=['AUC'])\n",
        "    model1.fit(X_train,y_train,cat_features=cat_col,eval_set=(X_val, y_val),early_stopping_rounds=30,verbose=100)\n",
        "    testpred1 = model1.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred1))\n",
        "    print(\"Test ROC AUC for model 1: %.4f\"%(roc_auc_score(y_val, testpred1)))\n",
        "    \n",
        "    model2 = cat.CatBoostClassifier(learning_rate = 0.04,random_state=42,scale_pos_weight=7, custom_metric=['AUC'])\n",
        "    model2.fit(X_train,y_train,cat_features=cat_col,eval_set=(X_val, y_val),early_stopping_rounds=40,verbose=100)\n",
        "    testpred2 = model2.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred2))\n",
        "    print(\"Test ROC AUC for model 2: %.4f\"%(roc_auc_score(y_val, testpred2)))\n",
        "    \n",
        "    model3 = cat.CatBoostClassifier(learning_rate = 0.05,random_state=42,scale_pos_weight=7, custom_metric=['AUC'])\n",
        "    model3.fit(X_train,y_train,cat_features=cat_col,eval_set=(X_val, y_val),early_stopping_rounds=20,verbose=100)\n",
        "    testpred3 = model3.predict_proba(X_val)[:,1]\n",
        "    test_roc_score.append(roc_auc_score(y_val, testpred3))\n",
        "    print(\"Test ROC AUC for model 3: %.4f\"%(roc_auc_score(y_val, testpred3)))\n",
        "    \n",
        "    wghts              = np.exp(-1000*np.array(test_roc_score/sum(test_roc_score)))\n",
        "    wghts              = wghts/sum(wghts)\n",
        "    \n",
        "    val_pred           = wghts[0]*testpred1+wghts[1]*testpred2 +wghts[2]*testpred3\n",
        "    print('validation roc_auc_score fold-',i+1,': ',roc_auc_score(y_val, val_pred))\n",
        "    \n",
        "    oof_pred[val_idx]  = val_pred\n",
        "    y_pred_final += (wghts[0]*model1.predict_proba(test)[:,1]+wghts[1]*model2.predict_proba(test)[:,1]+wghts[2]*model3.predict_proba(test)[:,1])/(n_splits)\n",
        "    \n",
        "    print('\\n')\n",
        "    \n",
        "print('OOF ROC_AUC_Score:- ',(roc_auc_score(Y,oof_pred)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Fold: 1\n",
            "\n",
            "0:\tlearn: 0.6731169\ttest: 0.6728809\tbest: 0.6728809 (0)\ttotal: 1.01s\tremaining: 16m 46s\n",
            "100:\tlearn: 0.4089662\ttest: 0.4075632\tbest: 0.4075632 (100)\ttotal: 1m 13s\tremaining: 10m 55s\n",
            "200:\tlearn: 0.4047124\ttest: 0.4044949\tbest: 0.4044949 (200)\ttotal: 2m 36s\tremaining: 10m 21s\n",
            "300:\tlearn: 0.4029850\ttest: 0.4039242\tbest: 0.4039242 (299)\ttotal: 3m 51s\tremaining: 8m 57s\n",
            "400:\tlearn: 0.4014316\ttest: 0.4035404\tbest: 0.4035404 (400)\ttotal: 5m 7s\tremaining: 7m 39s\n",
            "500:\tlearn: 0.3994814\ttest: 0.4033659\tbest: 0.4033659 (500)\ttotal: 6m 28s\tremaining: 6m 27s\n",
            "Stopped by overfitting detector  (30 iterations wait)\n",
            "\n",
            "bestTest = 0.403347371\n",
            "bestIteration = 517\n",
            "\n",
            "Shrink model to first 518 iterations.\n",
            "Test ROC AUC for model 1: 0.8743\n",
            "0:\tlearn: 0.6666592\ttest: 0.6663480\tbest: 0.6663480 (0)\ttotal: 885ms\tremaining: 14m 43s\n",
            "100:\tlearn: 0.4069097\ttest: 0.4059249\tbest: 0.4059249 (100)\ttotal: 1m 16s\tremaining: 11m 19s\n",
            "200:\tlearn: 0.4035630\ttest: 0.4040277\tbest: 0.4040277 (200)\ttotal: 2m 31s\tremaining: 10m 1s\n",
            "300:\tlearn: 0.4013781\ttest: 0.4036122\tbest: 0.4036073 (294)\ttotal: 3m 47s\tremaining: 8m 47s\n",
            "400:\tlearn: 0.3987241\ttest: 0.4033550\tbest: 0.4033550 (400)\ttotal: 5m 12s\tremaining: 7m 46s\n",
            "Stopped by overfitting detector  (40 iterations wait)\n",
            "\n",
            "bestTest = 0.40329772\n",
            "bestIteration = 456\n",
            "\n",
            "Shrink model to first 457 iterations.\n",
            "Test ROC AUC for model 2: 0.8744\n",
            "0:\tlearn: 0.6603108\ttest: 0.6599260\tbest: 0.6599260 (0)\ttotal: 992ms\tremaining: 16m 31s\n",
            "100:\tlearn: 0.4056441\ttest: 0.4048278\tbest: 0.4048278 (100)\ttotal: 1m 16s\tremaining: 11m 21s\n",
            "200:\tlearn: 0.4025651\ttest: 0.4036044\tbest: 0.4036044 (200)\ttotal: 2m 33s\tremaining: 10m 9s\n",
            "300:\tlearn: 0.3996372\ttest: 0.4032082\tbest: 0.4031968 (291)\ttotal: 3m 55s\tremaining: 9m 7s\n",
            "Stopped by overfitting detector  (20 iterations wait)\n",
            "\n",
            "bestTest = 0.4031920607\n",
            "bestIteration = 326\n",
            "\n",
            "Shrink model to first 327 iterations.\n",
            "Test ROC AUC for model 3: 0.8745\n",
            "validation roc_auc_score fold- 1 :  0.8744824582009757\n",
            "\n",
            "\n",
            "\n",
            "Fold: 2\n",
            "\n",
            "0:\tlearn: 0.6721733\ttest: 0.6722097\tbest: 0.6722097 (0)\ttotal: 841ms\tremaining: 14m\n",
            "100:\tlearn: 0.4069252\ttest: 0.4090053\tbest: 0.4090053 (100)\ttotal: 1m 13s\tremaining: 10m 51s\n",
            "200:\tlearn: 0.4028452\ttest: 0.4063401\tbest: 0.4063401 (200)\ttotal: 2m 30s\tremaining: 9m 59s\n",
            "300:\tlearn: 0.4010719\ttest: 0.4056936\tbest: 0.4056936 (300)\ttotal: 3m 43s\tremaining: 8m 40s\n",
            "400:\tlearn: 0.3992692\ttest: 0.4053058\tbest: 0.4053029 (394)\ttotal: 5m\tremaining: 7m 28s\n",
            "500:\tlearn: 0.3971656\ttest: 0.4051897\tbest: 0.4051838 (493)\ttotal: 6m 20s\tremaining: 6m 19s\n",
            "600:\tlearn: 0.3953317\ttest: 0.4050899\tbest: 0.4050882 (596)\ttotal: 7m 42s\tremaining: 5m 6s\n",
            "Stopped by overfitting detector  (30 iterations wait)\n",
            "\n",
            "bestTest = 0.4050877133\n",
            "bestIteration = 602\n",
            "\n",
            "Shrink model to first 603 iterations.\n",
            "Test ROC AUC for model 1: 0.8730\n",
            "0:\tlearn: 0.6654220\ttest: 0.6654688\tbest: 0.6654688 (0)\ttotal: 993ms\tremaining: 16m 32s\n",
            "100:\tlearn: 0.4046479\ttest: 0.4074657\tbest: 0.4074657 (100)\ttotal: 1m 14s\tremaining: 11m 6s\n",
            "200:\tlearn: 0.4013456\ttest: 0.4057721\tbest: 0.4057721 (200)\ttotal: 2m 30s\tremaining: 9m 57s\n",
            "300:\tlearn: 0.3991212\ttest: 0.4054442\tbest: 0.4054369 (298)\ttotal: 3m 46s\tremaining: 8m 45s\n",
            "400:\tlearn: 0.3965333\ttest: 0.4051789\tbest: 0.4051688 (391)\ttotal: 5m 5s\tremaining: 7m 35s\n",
            "Stopped by overfitting detector  (40 iterations wait)\n",
            "\n",
            "bestTest = 0.4051221182\n",
            "bestIteration = 454\n",
            "\n",
            "Shrink model to first 455 iterations.\n",
            "Test ROC AUC for model 2: 0.8731\n",
            "0:\tlearn: 0.6587904\ttest: 0.6588467\tbest: 0.6588467 (0)\ttotal: 921ms\tremaining: 15m 20s\n",
            "100:\tlearn: 0.4037457\ttest: 0.4065817\tbest: 0.4065817 (100)\ttotal: 1m 15s\tremaining: 11m 9s\n",
            "200:\tlearn: 0.4005887\ttest: 0.4055651\tbest: 0.4055651 (200)\ttotal: 2m 30s\tremaining: 9m 58s\n",
            "300:\tlearn: 0.3975991\ttest: 0.4051322\tbest: 0.4051159 (296)\ttotal: 3m 46s\tremaining: 8m 46s\n",
            "Stopped by overfitting detector  (20 iterations wait)\n",
            "\n",
            "bestTest = 0.405016845\n",
            "bestIteration = 323\n",
            "\n",
            "Shrink model to first 324 iterations.\n",
            "Test ROC AUC for model 3: 0.8731\n",
            "validation roc_auc_score fold- 2 :  0.873179816445148\n",
            "\n",
            "\n",
            "OOF ROC_AUC_Score:-  0.8737724421475705\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FosX5XOL0XMl"
      },
      "source": [
        "train_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.25,random_state=1,shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gv0VTLFe21tt",
        "outputId": "cf10c9ab-0b77-41a9-fb43-d057008ff075"
      },
      "source": [
        "model=GaussianNB()\n",
        "model.fit(train_x,train_y)\n",
        "o=model.predict(test_x)\n",
        "print(accuracy_score(test_y,o))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.726478057038677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-7FkeNN3MKF",
        "outputId": "b5590638-7b13-4f17-925e-05043f1d37e3"
      },
      "source": [
        "!pip install catboost \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (0.25.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (4.4.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.19.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (1.3.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.10.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laLrNZUv4Xyi"
      },
      "source": [
        "import catboost as cat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDewu2ZGnWqL"
      },
      "source": [
        "m1=y_pred_final"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z47cowaUpggU",
        "outputId": "d62af16d-52a8-4c53-a64c-5cce89206821"
      },
      "source": [
        "pre=pre*0.5 +df3['0']*0.5\n",
        "pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         0.223095\n",
              "1         0.973336\n",
              "2         0.281121\n",
              "3         0.141629\n",
              "4         0.136330\n",
              "            ...   \n",
              "105307    0.995142\n",
              "105308    0.891831\n",
              "105309    0.339192\n",
              "105310    0.680837\n",
              "105311    0.264482\n",
              "Name: 0, Length: 105312, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqVrVFHBpuij",
        "outputId": "a748e0ed-f599-4d9a-bbd6-85b7ff27cdcd"
      },
      "source": [
        "y_pred_final"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.22109801, 0.97335096, 0.27968477, ..., 0.32779139, 0.67609816,\n",
              "       0.26583231])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "jZdgLfi619NL",
        "outputId": "d83935c2-0891-42a6-d1a6-179de201863c"
      },
      "source": [
        "df3=pd.read_csv('/content/doccc20.csv')\n",
        "df3.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.223095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.973336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.281121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.141629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.136330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0         0\n",
              "0           0  0.223095\n",
              "1           1  0.973336\n",
              "2           2  0.281121\n",
              "3           3  0.141629\n",
              "4           4  0.136330"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7PTYSc42TR3"
      },
      "source": [
        "df3.drop(['Unnamed: 0'],axis=1,inplace=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ6iuC554rI9",
        "outputId": "371dd0e1-59c3-4068-bbf5-ea97efc6c28a"
      },
      "source": [
        "pre=model4.predict_proba(test)[:,1]\n",
        "pre"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.05387029, 0.844847  , 0.05202898, ..., 0.08730729, 0.21979302,\n",
              "       0.04923308], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB2rBVsi5jyf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "37297abd-7a2b-49fd-e4fe-684350afc32f"
      },
      "source": [
        "df4=pd.DataFrame(pre)\n",
        "df4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.223095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.973336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.281121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.141629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.136330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105307</th>\n",
              "      <td>0.995142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105308</th>\n",
              "      <td>0.891831</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105309</th>\n",
              "      <td>0.339192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105310</th>\n",
              "      <td>0.680837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105311</th>\n",
              "      <td>0.264482</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>105312 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0\n",
              "0       0.223095\n",
              "1       0.973336\n",
              "2       0.281121\n",
              "3       0.141629\n",
              "4       0.136330\n",
              "...          ...\n",
              "105307  0.995142\n",
              "105308  0.891831\n",
              "105309  0.339192\n",
              "105310  0.680837\n",
              "105311  0.264482\n",
              "\n",
              "[105312 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXA1N3E15xCW"
      },
      "source": [
        "df4.to_csv('doccc20.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMPXI-WHKamV"
      },
      "source": [
        "def frequency_encoding(column_name,output_column_name,df):\n",
        "    fe_pol = (df.groupby(column_name).size()) / len(df)\n",
        "    df[output_column_name] = df[column_name].apply(lambda x : fe_pol[x])\n",
        "\n",
        "\n",
        "def feature_engineering(df):\n",
        "    le = LabelEncoder()\n",
        "    \n",
        "     #Interaction Feature (Combining 2 categorical features and performing frequency encoding)\n",
        "        \n",
        "    cat_features=[]\n",
        "    le_features=[]\n",
        "    columns=['City_Code','Accomodation_Type','Reco_Insurance_Type','Health Indicator','Is_Spouse','Region_Code','Holding_Policy_Type','Reco_Policy_Cat']\n",
        "\n",
        "    comb = combinations(columns, 2) \n",
        "\n",
        "    for i in list(comb):  \n",
        "        df[f'{i[0]}_{i[1]}']=df[i[0]].astype(str)+'_'+df[i[1]].astype(str)\n",
        "        df[f'{i[0]}_{i[1]}_le']=le.fit_transform(df[f'{i[0]}_{i[1]}'])\n",
        "        le_features.append(f'{i[0]}_{i[1]}_le')\n",
        "        frequency_encoding(f'{i[0]}_{i[1]}',f'{i[0]}_{i[1]}',df)\n",
        "        cat_features.append(f'{i[0]}_{i[1]}')   \n",
        "        \n",
        "    #Frequency Encoding\n",
        "    \n",
        "    frequency_encoding('Region_Code','Region_Code_fe',df)\n",
        "    frequency_encoding('Reco_Policy_Cat','Reco_Policy_Cat_fe',df)\n",
        "    \n",
        "    #Deriving characteristics of each city by creating aggregate features\n",
        "    \n",
        "    city_aggregate_features = df.groupby(['City_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    city_aggregate_features.columns = ['city_aggregate_features' + '_'.join(c).strip('_') for c in city_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_aggregate_features, on = ['City_Code'], how='left')\n",
        "\n",
        " \n",
        "    city_region_aggregate_features = df.groupby(['City_Code','Region_Code']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'],  \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    city_region_aggregate_features.columns = ['city_region_aggregate_features' + '_'.join(c).strip('_') for c in city_region_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_region_aggregate_features, on = ['City_Code','Region_Code'], how='left')\n",
        "\n",
        "    city_recopolicycat_aggregate_features = df.groupby(['City_Code','Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] \n",
        "                                                     })\n",
        "    city_recopolicycat_aggregate_features.columns = ['city_recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_recopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_recopolicycat_aggregate_features, on = ['City_Code','Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    city_regioncoderecopolicycat_aggregate_features = df.groupby(['City_Code','Region_Code_Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'Reco_Policy_Cat': ['nunique','count'] ,\n",
        "                                                     })\n",
        "\n",
        "    city_regioncoderecopolicycat_aggregate_features.columns = ['city_regioncoderecopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in city_regioncoderecopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, city_regioncoderecopolicycat_aggregate_features, on = ['City_Code','Region_Code_Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    for i in cat_features:\n",
        "        df[f'city_{i}_max']=df.groupby('City_Code')[i].transform('max')\n",
        "        df[f'city_{i}_min']=df.groupby('City_Code')[i].transform('min')\n",
        "        df[f'city_{i}_mean']=df.groupby('City_Code')[i].transform('mean')\n",
        "        df[f'city_{i}_std']=df.groupby('City_Code')[i].transform('std')\n",
        "\n",
        "    \n",
        "        df[f'city_region_{i}_max']=df.groupby(['City_Code','Region_Code'])[i].transform('max')\n",
        "        df[f'city_region_{i}_min']=df.groupby(['City_Code','Region_Code'])[i].transform('min')\n",
        "        df[f'city_region_{i}_mean']=df.groupby(['City_Code','Region_Code'])[i].transform('mean')\n",
        "        df[f'city_region_{i}_std']=df.groupby(['City_Code','Region_Code'])[i].transform('std')\n",
        "\n",
        "    \n",
        "        df[f'city_recopolicycat_{i}_max']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('max')\n",
        "        df[f'city_recopolicycat_{i}_min']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('min')\n",
        "        df[f'city_recopolicycat_{i}_mean']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('mean')\n",
        "        df[f'city_recopolicycat_{i}_std']=df.groupby(['City_Code','Reco_Policy_Cat'])[i].transform('std')\n",
        "        \n",
        "    \n",
        "    #features on reco_policy_cat\n",
        "    \n",
        "    recopolicycat_aggregate_features = df.groupby(['Reco_Policy_Cat']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    recopolicycat_aggregate_features.columns = ['recopolicycat_aggregate_features' + '_'.join(c).strip('_') for c in recopolicycat_aggregate_features.columns]\n",
        "    df = pd.merge(df, recopolicycat_aggregate_features, on = ['Reco_Policy_Cat'], how='left')\n",
        "        \n",
        "        \n",
        "\n",
        "    #features on Holding_Policy_Type \n",
        "    \n",
        "    holdingpolicytype_aggregate_features = df.groupby(['Holding_Policy_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std'], \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Accomodation_Type': ['nunique','count'],\n",
        "                                                     'Reco_Insurance_Type': ['nunique','count'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    holdingpolicytype_aggregate_features.columns = ['holdingpolicytype_aggregate_features' + '_'.join(c).strip('_') for c in holdingpolicytype_aggregate_features.columns]\n",
        "    df = pd.merge(df, holdingpolicytype_aggregate_features, on = ['Holding_Policy_Type'], how='left')\n",
        "    \n",
        "    #Deriving characteristics of Accomodation_Type by creating aggregate features\n",
        "    \n",
        "    Accomodation_Type_aggregate_features = df.groupby(['Accomodation_Type']).agg({'Lower_Age': ['mean', 'max', 'min','std'],\n",
        "                                                     'Reco_Policy_Premium': ['mean', 'max', 'min','std','sum'],   \n",
        "                                                     'Region_Code': ['nunique','count'], \n",
        "                                                     'Reco_Insurance_Type': ['nunique'] ,\n",
        "                                                     'Health Indicator': ['nunique','count'] ,\n",
        "                                                     'Holding_Policy_Type': ['nunique','count'] ,\n",
        "                                                     'City_Code': ['nunique','count'] ,\n",
        "                                                     })\n",
        "    Accomodation_Type_aggregate_features.columns = ['Accomodation_Type_aggregate_features' + '_'.join(c).strip('_') for c in Accomodation_Type_aggregate_features.columns]\n",
        "    df = pd.merge(df, Accomodation_Type_aggregate_features, on = ['Accomodation_Type'], how='left')\n",
        "    \n",
        "    #Deriving characteristics of Interaction_features by creating aggregate features (These interaction feature are selected for aggregating based on its feature importance)\n",
        "    \n",
        "    Region_CodeReco_Policy_Cat_grpd = df.groupby(['Region_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    Region_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_Region_Code_Reco_Policy_Cat_' + '_'.join(c).strip('_') for c in Region_CodeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, Region_CodeReco_Policy_Cat_grpd, on = ['Region_Code_Reco_Policy_Cat'], how='left')\n",
        "\n",
        "\n",
        "    City_CodeRegion_Code_grpd = df.groupby(['City_Code_Region_Code']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    City_CodeRegion_Code_grpd.columns = ['grpd_by_City_CodeRegion_Code_' + '_'.join(c).strip('_') for c in City_CodeRegion_Code_grpd.columns]\n",
        "    df = pd.merge(df, City_CodeRegion_Code_grpd, on = ['City_Code_Region_Code'], how='left')\n",
        "\n",
        "\n",
        "    City_CodeReco_Policy_Cat_grpd = df.groupby(['City_Code_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    City_CodeReco_Policy_Cat_grpd.columns = ['grpd_by_City_CodeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in City_CodeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, City_CodeReco_Policy_Cat_grpd, on = ['City_Code_Reco_Policy_Cat'], how='left')\n",
        "\n",
        "\n",
        "    Holding_Policy_TypeReco_Policy_Cat_grpd = df.groupby(['Holding_Policy_Type_Reco_Policy_Cat']).agg({ 'Reco_Policy_Premium': ['mean', 'max', 'min', 'std']})                                                              \n",
        "                                                     \n",
        "    Holding_Policy_TypeReco_Policy_Cat_grpd.columns = ['grpd_by_Holding_Policy_TypeReco_Policy_Cat_' + '_'.join(c).strip('_') for c in Holding_Policy_TypeReco_Policy_Cat_grpd.columns]\n",
        "    df = pd.merge(df, Holding_Policy_TypeReco_Policy_Cat_grpd, on = ['Holding_Policy_Type_Reco_Policy_Cat'], how='left')\n",
        "    \n",
        "    return df,le_features"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}